{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"_wU3ca3vBxL4"},"outputs":[],"source":["# STEP 1: Force CPU only\n","import os\n","os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\"  # Disable GPU completely"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SdxizChAB0L5"},"outputs":[],"source":["# STEP 2: Install required packages\n","!pip install -q kaggle timm albumentations\n","!pip install -q seaborn scikit-learn"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rREJ5Lyx3n-d"},"outputs":[],"source":["# STEP 3: Import libraries\n","import os\n","import pandas as pd\n","import numpy as np\n","import seaborn as sns\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n","import matplotlib.pyplot as plt\n","import shutil\n","import zipfile\n","import tensorflow as tf\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import LabelEncoder\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","from tensorflow.keras.applications import MobileNetV2\n","from tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Dropout"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"eV4LBp1SnzLU"},"outputs":[],"source":["# STEP 4: Upload kaggle.json to access dataset\n","from google.colab import files\n","files.upload()  # Upload your kaggle.json\n","\n","# Save to correct location\n","!mkdir -p ~/.kaggle\n","!mv kaggle.json ~/.kaggle/\n","!chmod 600 ~/.kaggle/kaggle.json"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CoHVqPOOJG_w"},"outputs":[],"source":["# Download dataset\n","!kaggle datasets download -d kmader/skin-cancer-mnist-ham10000\n","\n","# Unzip\n","!unzip -q skin-cancer-mnist-ham10000.zip -d ham10000_data"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ptlfzbjBJO6d"},"outputs":[],"source":["# STEP 3: Load Metadata\n","df = pd.read_csv(\"ham10000_data/HAM10000_metadata.csv\")\n","\n","# STEP 4: Fix image paths from both folders\n","image_dir1 = \"ham10000_data/HAM10000_images_part_1\"\n","image_dir2 = \"ham10000_data/HAM10000_images_part_2\"\n","\n","all_image_paths = {\n","    os.path.splitext(f)[0]: os.path.join(image_dir1, f)\n","    for f in os.listdir(image_dir1) if f.endswith(\".jpg\")\n","}\n","all_image_paths.update({\n","    os.path.splitext(f)[0]: os.path.join(image_dir2, f)\n","    for f in os.listdir(image_dir2) if f.endswith(\".jpg\")\n","})\n","\n","df[\"path\"] = df[\"image_id\"].map(all_image_paths)\n","df = df.dropna(subset=[\"path\"])\n","df[\"label\"] = df[\"dx\"]\n","\n","# STEP 5: Train/Validation Split\n","train_df, val_df = train_test_split(df, test_size=0.2, stratify=df[\"label\"], random_state=42)\n","\n","# STEP 6: Data Augmentation\n","train_gen = ImageDataGenerator(rescale=1./255, horizontal_flip=True, zoom_range=0.2)\n","val_gen = ImageDataGenerator(rescale=1./255)\n","\n","train_generator = train_gen.flow_from_dataframe(\n","    train_df,\n","    x_col=\"path\", y_col=\"label\",\n","    target_size=(224, 224),\n","    class_mode=\"categorical\",\n","    batch_size=16,\n","    shuffle=True\n",")\n","\n","val_generator = val_gen.flow_from_dataframe(\n","    val_df,\n","    x_col=\"path\", y_col=\"label\",\n","    target_size=(224, 224),\n","    class_mode=\"categorical\",\n","    batch_size=16,\n","    shuffle=False\n",")\n","\n","# ✅ FIX: Use class indices to determine number of output classes\n","num_classes = len(train_generator.class_indices)\n","\n","# STEP 7: Build the Model\n","base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n","x = base_model.output\n","x = GlobalAveragePooling2D()(x)\n","x = Dropout(0.3)(x)\n","x = Dense(128, activation='relu')(x)\n","predictions = Dense(num_classes, activation='softmax')(x)\n","model = Model(inputs=base_model.input, outputs=predictions)\n","\n","# Freeze base model layers\n","for layer in base_model.layers:\n","    layer.trainable = False\n","\n","# Compile model\n","model.compile(optimizer=Adam(learning_rate=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])\n","\n","# STEP 8: Callbacks\n","early_stop = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n","checkpoint = ModelCheckpoint(\"mobilenetv2_best.h5\", monitor=\"val_accuracy\", save_best_only=True)\n","\n","# STEP 9: Train the Model\n","history = model.fit(\n","    train_generator,\n","    validation_data=val_generator,\n","    epochs=20,\n","    callbacks=[early_stop, checkpoint]\n",")"]},{"cell_type":"code","source":["import os\n","\n","# Get all image paths from both folders\n","image_dir1 = \"ham10000_data/HAM10000_images_part_1\"\n","image_dir2 = \"ham10000_data/HAM10000_images_part_2\"\n","\n","all_image_paths = {\n","    os.path.splitext(f)[0]: os.path.join(image_dir1, f)\n","    for f in os.listdir(image_dir1)\n","    if f.endswith(\".jpg\")\n","}\n","all_image_paths.update({\n","    os.path.splitext(f)[0]: os.path.join(image_dir2, f)\n","    for f in os.listdir(image_dir2)\n","    if f.endswith(\".jpg\")\n","})\n","\n","# Now map correct paths to df\n","df[\"path\"] = df[\"image_id\"].map(all_image_paths)\n","\n","# Drop rows with missing images (just in case)\n","df = df.dropna(subset=[\"path\"])"],"metadata":{"id":"9CMoFnhn9Zp6"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WeI2VynowJT9"},"outputs":[],"source":["# STEP 7: Build MobileNetV2 Model\n","base_model = MobileNetV2(include_top=False, weights=\"imagenet\", input_shape=(224, 224, 3))\n","base_model.trainable = False  # Freeze backbone\n","\n","# Add custom head\n","x = GlobalAveragePooling2D()(base_model.output)\n","x = Dense(128, activation='relu')(x)\n","x = Dropout(0.3)(x)\n","output = Dense(num_classes, activation='softmax')(x)\n","\n","model = Model(inputs=base_model.input, outputs=output)\n","model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n","\n","model.summary()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"w7-loZDyxJqk"},"outputs":[],"source":["# STEP 8: Train the Model\n","history = model.fit(\n","    train_generator,\n","    validation_data=val_generator,\n","    epochs=5,  # Use 3–5 for now to verify\n","    verbose=1\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lCbOCKIDxZYY"},"outputs":[],"source":["# STEP 9: Plot Training Results\n","plt.plot(history.history[\"accuracy\"], label=\"Train Accuracy\")\n","plt.plot(history.history[\"val_accuracy\"], label=\"Validation Accuracy\")\n","plt.legend()\n","plt.title(\"Model Accuracy\")\n","plt.xlabel(\"Epoch\")\n","plt.ylabel(\"Accuracy\")\n","plt.grid()\n","plt.show()"]}],"metadata":{"colab":{"provenance":[{"file_id":"1_-Ah_2lW4Y58jTkVB6ZOUHwwYsnhV42P","timestamp":1753195609384}],"authorship_tag":"ABX9TyMRqJPIvGzWSBCfpKxX2KyW"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}